{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchviz import make_dot\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "x = np.random.rand(100,1)\n",
    "y = 1 + 2* x + 0.1 * np.random.rand(100, 1)\n",
    "N = 80\n",
    "x_train, y_train = x[:N], y[:N]\n",
    "x_test, y_test = x[N:], y[N:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'torch.Tensor'> torch.cuda.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "x_train_tensor = torch.from_numpy(x_train).float().to(device)\n",
    "y_train_tensor = torch.from_numpy(y_train).float().to(device)\n",
    "print(type(x_train), type(x_train_tensor), x_train_tensor.type())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1681], requires_grad=True) tensor([0.2846], requires_grad=True)\n",
      "tensor([-0.2844], device='cuda:0', grad_fn=<CopyBackwards>) tensor([-0.6401], device='cuda:0', grad_fn=<CopyBackwards>)\n",
      "tensor([-1.6705], device='cuda:0', requires_grad=True) tensor([-0.0494], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#FIRST\n",
    "a = torch.randn(1, requires_grad = True, dtype = torch.float)\n",
    "b = torch.randn(1, requires_grad = True, dtype = torch.float)\n",
    "print(a, b)\n",
    "#Second\n",
    "a = torch.randn(1, requires_grad = True, dtype = torch.float).to(device)\n",
    "b = torch.randn(1, requires_grad = True, dtype = torch.float).to(device)\n",
    "print(a, b)\n",
    "# Third\n",
    "a = torch.randn(1,  dtype = torch.float).to(device)\n",
    "b = torch.randn(1, dtype = torch.float).to(device)\n",
    "a.requires_grad_()\n",
    "b.requires_grad_()\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every method that ends with underscore ( _ ) makes change in-place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0396], device='cuda:0', requires_grad=True) tensor([-0.1836], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Forth. The best method\n",
    "a = torch.randn(1, requires_grad = True, dtype = torch.float, device = device)\n",
    "b = torch.randn(1, requires_grad = True, dtype = torch.float, device = device)\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0482], device='cuda:0', requires_grad=True) tensor([1.9983], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-1\n",
    "n_epochs = 1000\n",
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad = True, dtype = torch.float, device = device)\n",
    "b = torch.randn(1, requires_grad = True, dtype = torch.float, device = device)\n",
    "for epoch in range(n_epochs):\n",
    "    yhat = a + b * x_train_tensor\n",
    "    error = y_train_tensor - yhat\n",
    "    loss = (error**2).mean()\n",
    "    loss.backward()\n",
    "    #print(a.grad)\n",
    "    #print(b.grad)\n",
    "    with torch.no_grad():\n",
    "        a -= lr * a.grad\n",
    "        b -= lr * b.grad\n",
    "    a.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "print(a, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"168pt\" height=\"171pt\"\r\n",
       " viewBox=\"0.00 0.00 168.00 171.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 167)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-167 164,-167 164,4 -4,4\"/>\r\n",
       "<!-- 2256354604680 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>2256354604680</title>\r\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"116,-21 26,-21 26,-0 116,-0 116,-21\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"71\" y=\"-7.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">AddBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2256352684232 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>2256352684232</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"54,-92 0,-92 0,-57 54,-57 54,-92\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-64.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\"> (1)</text>\r\n",
       "</g>\r\n",
       "<!-- 2256352684232&#45;&gt;2256354604680 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>2256352684232&#45;&gt;2256354604680</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M38.7912,-56.8851C44.8369,-48.3661 52.2043,-37.9849 58.3663,-29.3021\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"61.3122,-31.1985 64.2455,-21.0178 55.6037,-27.1472 61.3122,-31.1985\"/>\r\n",
       "</g>\r\n",
       "<!-- 2256354605832 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2256354605832</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"160,-85 72,-85 72,-64 160,-64 160,-85\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"116\" y=\"-71.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">MulBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2256354605832&#45;&gt;2256354604680 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>2256354605832&#45;&gt;2256354604680</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M108.969,-63.8125C102.337,-54.6755 92.2304,-40.7508 84.1113,-29.5644\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"86.8369,-27.3612 78.1304,-21.3241 81.1718,-31.473 86.8369,-27.3612\"/>\r\n",
       "</g>\r\n",
       "<!-- 2256350374216 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>2256350374216</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"143,-163 89,-163 89,-128 143,-128 143,-163\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"116\" y=\"-135.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\"> (1)</text>\r\n",
       "</g>\r\n",
       "<!-- 2256350374216&#45;&gt;2256354605832 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>2256350374216&#45;&gt;2256354605832</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M116,-127.797C116,-117.956 116,-105.453 116,-95.141\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"119.5,-95.0398 116,-85.0398 112.5,-95.0398 119.5,-95.0398\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x20d54cf5408>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad = True, dtype = torch.float, device= device)\n",
    "b = torch.randn(1, requires_grad = True, dtype = torch.float, device= device)\n",
    " \n",
    "yhat = a + b * x_train_tensor\n",
    "error = y_train_tensor - yhat\n",
    "loss = (error**2).mean()\n",
    "make_dot(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"98pt\" height=\"157pt\"\r\n",
       " viewBox=\"0.00 0.00 98.00 157.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 153)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-153 94,-153 94,4 -4,4\"/>\r\n",
       "<!-- 2256354606152 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>2256354606152</title>\r\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"90,-21 0,-21 0,-0 90,-0 90,-21\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"45\" y=\"-7.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">AddBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2256280690056 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>2256280690056</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"89,-78 1,-78 1,-57 89,-57 89,-78\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"45\" y=\"-64.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">MulBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2256280690056&#45;&gt;2256354606152 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>2256280690056&#45;&gt;2256354606152</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M45,-56.9197C45,-49.9083 45,-40.1442 45,-31.4652\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"48.5001,-31.3408 45,-21.3408 41.5001,-31.3409 48.5001,-31.3408\"/>\r\n",
       "</g>\r\n",
       "<!-- 2256354608648 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2256354608648</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"72,-149 18,-149 18,-114 72,-114 72,-149\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"45\" y=\"-121.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\"> (1)</text>\r\n",
       "</g>\r\n",
       "<!-- 2256354608648&#45;&gt;2256280690056 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>2256354608648&#45;&gt;2256280690056</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M45,-113.885C45,-105.994 45,-96.5046 45,-88.2477\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"48.5001,-88.0177 45,-78.0178 41.5001,-88.0178 48.5001,-88.0177\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x20d59359448>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_nograd = torch.randn(1, requires_grad = False, dtype = torch.float, device= device)\n",
    "b = torch.randn(1, requires_grad = True, dtype = torch.float, device= device)\n",
    "\n",
    "yhat = a_nograd + b * x_train_tensor\n",
    "make_dot(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very good example about dynamical computational grapg in Pytorch\n",
    "Это прямо очень крто, как мы можем между собой объединять различные losses\n",
    "и вообще как мы можем всё это компоновать, это удивительно на самом деле. Теперь я понимаю почему его так любят, это по истине очень гибкая система. Мне кажется я её теперь тоже очень сильно полюблю\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"278pt\" height=\"399pt\"\r\n",
       " viewBox=\"0.00 0.00 278.00 399.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 395)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-395 274,-395 274,4 -4,4\"/>\r\n",
       "<!-- 2256354610056 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>2256354610056</title>\r\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"202,-21 112,-21 112,-0 202,-0 202,-21\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"157\" y=\"-7.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">AddBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2256354608392 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>2256354608392</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"167,-78 71,-78 71,-57 167,-57 167,-78\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"119\" y=\"-64.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">MeanBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2256354608392&#45;&gt;2256354610056 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>2256354608392&#45;&gt;2256354610056</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M125.619,-56.9197C130.786,-49.4409 138.117,-38.8301 144.394,-29.745\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"147.396,-31.5577 150.201,-21.3408 141.637,-27.5786 147.396,-31.5577\"/>\r\n",
       "</g>\r\n",
       "<!-- 2256354693768 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2256354693768</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"155.5,-135 64.5,-135 64.5,-114 155.5,-114 155.5,-135\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"110\" y=\"-121.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">PowBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2256354693768&#45;&gt;2256354608392 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>2256354693768&#45;&gt;2256354608392</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M111.568,-113.92C112.715,-106.908 114.313,-97.1442 115.733,-88.4652\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"119.229,-88.7748 117.39,-78.3408 112.321,-87.6443 119.229,-88.7748\"/>\r\n",
       "</g>\r\n",
       "<!-- 2256354693832 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>2256354693832</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"154,-192 66,-192 66,-171 154,-171 154,-192\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"110\" y=\"-178.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">SubBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2256354693832&#45;&gt;2256354693768 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>2256354693832&#45;&gt;2256354693768</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M110,-170.92C110,-163.908 110,-154.144 110,-145.465\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"113.5,-145.341 110,-135.341 106.5,-145.341 113.5,-145.341\"/>\r\n",
       "</g>\r\n",
       "<!-- 2256354694088 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>2256354694088</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"155,-249 65,-249 65,-228 155,-228 155,-249\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"110\" y=\"-235.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">AddBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2256354694088&#45;&gt;2256354693832 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>2256354694088&#45;&gt;2256354693832</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M110,-227.92C110,-220.908 110,-211.144 110,-202.465\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"113.5,-202.341 110,-192.341 106.5,-202.341 113.5,-202.341\"/>\r\n",
       "</g>\r\n",
       "<!-- 2256352684232 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>2256352684232</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"54,-320 0,-320 0,-285 54,-285 54,-320\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-292.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\"> (1)</text>\r\n",
       "</g>\r\n",
       "<!-- 2256352684232&#45;&gt;2256354694088 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>2256352684232&#45;&gt;2256354694088</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M49.2425,-284.885C61.6073,-275.649 76.9028,-264.223 89.0535,-255.147\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"91.3415,-257.806 97.2585,-249.018 87.1523,-252.198 91.3415,-257.806\"/>\r\n",
       "</g>\r\n",
       "<!-- 2256354694216 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>2256354694216</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"160,-313 72,-313 72,-292 160,-292 160,-313\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"116\" y=\"-299.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">MulBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2256354694216&#45;&gt;2256354694088 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>2256354694216&#45;&gt;2256354694088</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M115.063,-291.813C114.231,-283.218 112.989,-270.388 111.944,-259.585\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"115.398,-258.94 110.951,-249.324 108.43,-259.615 115.398,-258.94\"/>\r\n",
       "</g>\r\n",
       "<!-- 2256354608648 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>2256354608648</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"196,-391 142,-391 142,-356 196,-356 196,-391\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"169\" y=\"-363.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\"> (1)</text>\r\n",
       "</g>\r\n",
       "<!-- 2256354608648&#45;&gt;2256354694216 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>2256354608648&#45;&gt;2256354694216</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M156.17,-355.797C148.128,-345.327 137.773,-331.847 129.591,-321.194\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"132.195,-318.838 123.328,-313.04 126.644,-323.102 132.195,-318.838\"/>\r\n",
       "</g>\r\n",
       "<!-- 2256354693960 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>2256354693960</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"266,-313 178,-313 178,-292 266,-292 266,-313\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"222\" y=\"-299.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">MulBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2256354608648&#45;&gt;2256354693960 -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>2256354608648&#45;&gt;2256354693960</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M181.83,-355.797C189.872,-345.327 200.227,-331.847 208.409,-321.194\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"211.356,-323.102 214.672,-313.04 205.805,-318.838 211.356,-323.102\"/>\r\n",
       "</g>\r\n",
       "<!-- 2256354693896 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>2256354693896</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"270,-135 174,-135 174,-114 270,-114 270,-135\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"222\" y=\"-121.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">MeanBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2256354693896&#45;&gt;2256354610056 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>2256354693896&#45;&gt;2256354610056</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M216.458,-113.951C205.665,-95.3533 181.66,-53.9919 167.676,-29.8964\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"170.575,-27.917 162.528,-21.0249 164.52,-31.4307 170.575,-27.917\"/>\r\n",
       "</g>\r\n",
       "<!-- 2256354609352 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>2256354609352</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"266,-249 178,-249 178,-228 266,-228 266,-249\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"222\" y=\"-235.4\" font-family=\"Times New Roman,serif\" font-size=\"12.00\">SubBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2256354609352&#45;&gt;2256354693896 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>2256354609352&#45;&gt;2256354693896</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M222,-227.951C222,-209.684 222,-169.455 222,-145.198\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"225.5,-145.025 222,-135.025 218.5,-145.025 225.5,-145.025\"/>\r\n",
       "</g>\r\n",
       "<!-- 2256354693960&#45;&gt;2256354609352 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>2256354693960&#45;&gt;2256354609352</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M222,-291.813C222,-283.218 222,-270.388 222,-259.585\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"225.5,-259.324 222,-249.324 218.5,-259.324 225.5,-259.324\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x20d59370208>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = a + b * x_train_tensor\n",
    "error = y_train_tensor - yhat\n",
    "\n",
    "loss = (error**2).mean()\n",
    "if loss >0:\n",
    "    yhat2 = b* x_train_tensor\n",
    "    error2 = y_train_tensor - yhat2\n",
    "loss += error2.mean()\n",
    "make_dot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Parameters before updates via learning\n",
      " tensor([0.1940], device='cuda:0', requires_grad=True) tensor([0.1391], device='cuda:0', requires_grad=True)\n",
      " Parameters before updates via learning\n",
      " tensor([1.0482], device='cuda:0', requires_grad=True) tensor([1.9983], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Now we implement another optimizer\n",
    "\n",
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad = True, dtype = torch.float, device= device)\n",
    "b = torch.randn(1, requires_grad = True, dtype = torch.float, device= device)\n",
    "print(\" Parameters before updates via learning\\n\", a, b)\n",
    "lr = 0.1\n",
    "n_epochs = 1000\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction = 'mean')\n",
    "optimizer = optim.SGD([a, b], lr = lr)\n",
    "for epoch in range(n_epochs):\n",
    "    yhat = a + b * x_train_tensor\n",
    "    #No more it because it had implemented\n",
    "    #error = y_train_tensor - yhat\n",
    "    #loss = (error**2).mean()\n",
    "    loss = loss_fn(y_train_tensor, yhat)\n",
    "    \n",
    "    loss.backward()\n",
    "    # with torch.no_grad() NO MORE IT\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "print(\" Parameters before updates via learning\\n\",a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's go into model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Optimizer\n",
    "- Loss\n",
    "- Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManualLinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()# initilize parent class\n",
    "        # we need to send our model to the same device where the data is\n",
    "        self.a = nn.Parameter(torch.randn(1, requires_grad = True, dtype = torch.float))\n",
    "        self.b = nn.Parameter(torch.randn(1, requires_grad = True, dtype = torch.float))   \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.a + self.b * x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_values([tensor([0.9307], device='cuda:0'), tensor([-0.3482], device='cuda:0')])\n",
      "OrderedDict([('a', tensor([1.0482], device='cuda:0')), ('b', tensor([1.9983], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(40)\n",
    "\n",
    "model = ManualLinearRegression().to(device)\n",
    "print(model.state_dict().values())\n",
    "\n",
    "lr = 0.1\n",
    "n_epochs = 1000\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction = 'mean')\n",
    "optimizer = optim.SGD(model.parameters(), lr = lr)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    model.train() # set our model in training mode\n",
    "    yhat = model(x_train_tensor)\n",
    "    \n",
    "    loss = loss_fn(y_train_tensor, yhat)\n",
    "    loss.backward()\n",
    "    #print(loss)\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nested model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerLinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1) # 1 input and 1 output\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Seconf approach more sequentialy\n",
    "model  = nn.Sequential(nn.Linear(1,1).to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'otimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-7615a1ba923f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-7615a1ba923f>\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m        \u001b[1;31m#updates parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0motimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'otimizer' is not defined"
     ]
    }
   ],
   "source": [
    "# we want take our life better\n",
    "def make_train_step(model, loss_fn, optimizer):\n",
    "    def train_step(x, y):\n",
    "        model.train()\n",
    "        yhat = model(x)         # make predict\n",
    "        \n",
    "        loss = loss_fn(y, yhat) #compute loss\n",
    "        loss.backward()         #compute gradients\n",
    "        \n",
    "        optimizer.step()        #updates parameters\n",
    "        otimizer.zero_grad()\n",
    "        return loss.item()\n",
    "    return train_step\n",
    "\n",
    "# Creates the train_step func for certain our model\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    loss = train_step(x_train_tensor, y_train_tensor)\n",
    "    losses.append(loss)\n",
    "    \n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Focus in dataset\n",
    "dataset in pytorch is represented by **Python class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, TensorDataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        self.x = x_tensor\n",
    "        self.y = y_tensor\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "x_train_tensor = torch.from_numpy(x_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "\n",
    "train_data = CustomDataset(x_train_tensor, y_train_tensor)\n",
    "print(train_data[1])\n",
    "\n",
    "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "print(train_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okey we know that we can create own dataset. It is very simple. And it is very good\n",
    "But it save on operative memory and process by CPU\n",
    "But we want on GPU. We can train downloading on GPU HOW\n",
    "List below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch DataLoader class for this job. We tell in which dataset to use. \n",
    "minibatch size, shuffle or not and so on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(dataset = train_data, batch_size = 16, shuffle=True)\n",
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        loss = train_step(x_batch, y_batch)\n",
    "        losses.append(loss)\n",
    "\n",
    "print(model.state_dict())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "x_tensor = torch.from_numpy(x).float()\n",
    "y_tensor = torch.from_numpy(x).float()\n",
    "\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [80,20])\n",
    "print(len(train_dataset), len(val_dataset))\n",
    "\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = 10)\n",
    "val_loader = DataLoader(dataset = val_dataset, batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataLoader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good pipeline for training\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        loss = train_step(x_batch, y_batch)\n",
    "        losses.append(loss)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in val_loader:\n",
    "            x_val = x_val.to(device)\n",
    "            y_val = y_val.to(device)\n",
    "            \n",
    "            model.eval()\n",
    "            yhat = model(x_val)\n",
    "            val_loss = loss_fn(y_val, yhat)\n",
    "            val_losses.append(val_loss)\n",
    "            \n",
    "            \n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
